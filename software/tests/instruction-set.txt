- rv32mi/breakpoint.s
- rv32mi/csr.s
- rv32mi/illegal.s
- rv32mi/lh-misaligned.s
- rv32mi/lw-misaligned.s
- rv32mi/ma_addr.s
- rv32mi/ma_fetch.s
- rv32mi/mcsr.s
- rv32mi/sbreak.s
- rv32mi/scall.s
- rv32mi/shamt.s
- rv32mi/sh-misaligned.s
- rv32mi/sw-misaligned.s
- rv32mi/zicntr.s
- rv32si/csr.s
- rv32si/dirty.s
- rv32si/ma_fetch.s
- rv32si/sbreak.s
- rv32si/scall.s
- rv32si/wfi.s
- rv32ua/amoadd_w.s          R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] + R[rS2]
- rv32ua/amoand_w.s          R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] & R[rS2]
- rv32ua/amomaxu_w.s
- rv32ua/amomax_w.s
- rv32ua/amominu_w.s
- rv32ua/amomin_w.s
- rv32ua/amoor_w.s           R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] | R[rS2]
- rv32ua/amoswap_w.s         R[rd] = M[R[rs1]]; M[R[rS1]] = R[rS2]
- rv32ua/amoxor_w.s          R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] ^ R[rS2]
- rv32ua/lrsc.s
- rv32uc/rvc.s
- rv32ud/fadd.s              F[rd] = F[rs1] + F[rs2]
- rv32ud/fclass.s            R[rd] = class(F[rs1])
- rv32ud/fcmp.s
- rv32ud/fcvt.s
- rv32ud/fcvt_w.s
- rv32ud/fdiv.s              F[rd] = F[rs1] / F[rs2]
- rv32ud/fmadd.s             F[rd] = F[rs1] * F[rs2] + F[rs3]
- rv32ud/fmin.s
- rv32ud/ldst.s
- rv32ud/move.s
- rv32ud/recoding.s
- rv32uf/fadd.s              F[rd] = F[rs1] + F[rs2]
- rv32uf/fclass.s            R[rd] = class(F[rs1])
- rv32uf/fcmp.s
- rv32uf/fcvt.s
- rv32uf/fcvt_w.s
- rv32uf/fdiv.s              F[rd] = F[rs1] / F[rs2]
- rv32uf/fmadd.s             F[rd] = F[rs1] * F[rs2] + F[rs3]
- rv32uf/fmin.s
- rv32uf/ldst.s
- rv32uf/move.s
- rv32uf/recoding.s
- rv32ui/addi.s              R[rd] = R[rs1] + imm
- rv32ui/add.s               R[rd] = R[rs1] + R[rs2]
- rv32ui/andi.s              R[rd] = R[rs1] & imm
- rv32ui/and.s               R[rd] = R[rs1] & R[rs2]
- rv32ui/auipc.s             R[rd] = PC + {imm, 12'b0}
- rv32ui/beq.s               if(R[rs1] == R[rs2]) PC = PC + {imm, 1'b0}
- rv32ui/bge.s               if(R[rs1] >= R[rs2]) PC = PC + {imm, 1'b0}
- rv32ui/bgeu.s              if(R[rs1] >= R[rs2]) PC = PC + {imm, 1'b0}
- rv32ui/blt.s               if(R[rs1] < R[rs2]) PC = PC + {imm, 1'b0}
- rv32ui/bltu.s              if(R[rs1] < R[rs2]) PC = PC + {imm, 1'b0}
- rv32ui/bne.s               if(R[rs1] != R[rs2]) PC = PC + {imm, 1'b0}
- rv32ui/fence_i.s
- rv32ui/jalr.s              R[rd] = PC + 4; PC = R[rs1] + imm
- rv32ui/jal.s               R[rd] = PC + 4; PC = PC + {imm, 1'b0}
- rv32ui/lb.s
- rv32ui/lbu.s
- rv32ui/lh.s
- rv32ui/lhu.s
- rv32ui/lui.s               R[rd] = {32b'imm<31>, imm, 12'b0}
- rv32ui/lw.s                R[rd] = {32'bM[](31), M[R[rs1]] + imm](31:0)}
- rv32ui/ma_data.s
- rv32ui/ori.s               R[rd] = R[rs1] | imm
- rv32ui/or.s                R[rd] = R[rs1] | R[rs2]
- rv32ui/sb.s                M[R[rs1] + imm](7:0) = R[rs2](7:0)
- rv32ui/sh.s                M[R[rs1] + imm](15:0) = R[rs2](15:0)
- rv32ui/simple.s
- rv32ui/slli.s              R[rd] = R[rs1] << imm
- rv32ui/sll.s               R[rd] = R[rs1] << R[rs2]
- rv32ui/slti.s              R[rd] = (R[rs1] < imm)? 1 : 0
- rv32ui/sltiu.s             R[rd] = (R[rs1] < imm)? 1 : 0
- rv32ui/slt.s               R[rd] = (R[rs1] < R[rs2])? 1 : 0
- rv32ui/sltu.s              R[rd] = (R[rs1] < R[rs2])? 1 : 0
- rv32ui/srai.s              R[rd] = R[rs1] >> imm
- rv32ui/sra.s               R[rd] = R[rs1] >> R[rs2]
- rv32ui/srli.s              R[rd] = R[rs1] >> imm
- rv32ui/srl.s               R[rd] = R[rs1] >> R[rs2]
- rv32ui/sub.s               R[rd] = R[rs1] - R[rs2]
- rv32ui/sw.s                M[R[rs1] + imm](31:0) = R[rs2](31:0)
- rv32ui/xori.s              R[rd] = R[rs1] ^ imm
- rv32ui/xor.s               R[rd] = R[rs1] ^ R[rs2]
- rv32um/div.s               R[rd] = (R[rs1] / R[rs2])
- rv32um/divu.s              R[rd] = (R[rs1] / R[rs2])
- rv32um/mulh.s              R[rd] = (R[rs1] * R[rs2])(127:64)
- rv32um/mulhsu.s            R[rd] = (R[rs1] * R[rs2])(127:64)
- rv32um/mulhu.s             R[rd] = (R[rs1] * R[rs2])(127:64)
- rv32um/mul.s               R[rd] = (R[rs1] * R[rs2])(63:0)
- rv32um/rem.s               R[rd] = (R[rs1] % R[rs2])
- rv32um/remu.s              R[rd] = (R[rs1] % R[rs2])
- rv32uzfh/fadd.s            F[rd] = F[rs1] + F[rs2]
- rv32uzfh/fclass.s          R[rd] = class(F[rs1])
- rv32uzfh/fcmp.s
- rv32uzfh/fcvt.s
- rv32uzfh/fcvt_w.s
- rv32uzfh/fdiv.s            F[rd] = F[rs1] / F[rs2]
- rv32uzfh/fmadd.s           F[rd] = F[rs1] * F[rs2] + F[rs3]
- rv32uzfh/fmin.s
- rv32uzfh/ldst.s
- rv32uzfh/move.s
- rv32uzfh/recoding.s
- rv64mi/access.s
- rv64mi/breakpoint.s
- rv64mi/csr.s
- rv64mi/illegal.s
- rv64mi/ld-misaligned.s
- rv64mi/lh-misaligned.s
- rv64mi/lw-misaligned.s
- rv64mi/ma_addr.s
- rv64mi/ma_fetch.s
- rv64mi/mcsr.s
- rv64mi/sbreak.s
- rv64mi/scall.s
- rv64mi/sd-misaligned.s
- rv64mi/sh-misaligned.s
- rv64mi/sw-misaligned.s
- rv64mi/zicntr.s
- rv64mzicbo/zero.s
- rv64si/csr.s
- rv64si/dirty.s
- rv64si/icache-alias.s
- rv64si/ma_fetch.s
- rv64si/sbreak.s
- rv64si/scall.s
- rv64si/wfi.s
- rv64ssvnapot/napot.s
- rv64ua/amoadd_d.s          R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] + R[rS2]
- rv64ua/amoadd_w.s          R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] + R[rS2]
- rv64ua/amoand_d.s          R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] & R[rS2]
- rv64ua/amoand_w.s          R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] & R[rS2]
- rv64ua/amomax_d.s
- rv64ua/amomaxu_d.s
- rv64ua/amomaxu_w.s
- rv64ua/amomax_w.s
- rv64ua/amomin_d.s
- rv64ua/amominu_d.s
- rv64ua/amominu_w.s
- rv64ua/amomin_w.s
- rv64ua/amoor_d.s           R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] | R[rS2]
- rv64ua/amoor_w.s           R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] | R[rS2]
- rv64ua/amoswap_d.s         R[rd] = M[R[rs1]]; M[R[rS1]] = R[rS2]
- rv64ua/amoswap_w.s         R[rd] = M[R[rs1]]; M[R[rS1]] = R[rS2]
- rv64ua/amoxor_d.s          R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] ^ R[rS2]
- rv64ua/amoxor_w.s          R[rd] = M[R[rs1]]; M[R[rS1]] = M[R[rs1]] ^ R[rS2]
- rv64ua/lrsc.s
- rv64uc/rvc.s
- rv64ud/fadd.s              F[rd] = F[rs1] + F[rs2]
- rv64ud/fclass.s            R[rd] = class(F[rs1])
- rv64ud/fcmp.s
- rv64ud/fcvt.s
- rv64ud/fcvt_w.s
- rv64ud/fdiv.s              F[rd] = F[rs1] / F[rs2]
- rv64ud/fmadd.s             F[rd] = F[rs1] * F[rs2] + F[rs3]
- rv64ud/fmin.s
- rv64ud/ldst.s
- rv64ud/move.s
- rv64ud/recoding.s
- rv64ud/structural.s
- rv64uf/fadd.s              F[rd] = F[rs1] + F[rs2]
- rv64uf/fclass.s            R[rd] = class(F[rs1])
- rv64uf/fcmp.s
- rv64uf/fcvt.s
- rv64uf/fcvt_w.s
- rv64uf/fdiv.s              F[rd] = F[rs1] / F[rs2]
- rv64uf/fmadd.s             F[rd] = F[rs1] * F[rs2] + F[rs3]
- rv64uf/fmin.s
- rv64uf/ldst.s
- rv64uf/move.s
- rv64uf/recoding.s
- rv64ui/addi.s              R[rd] = R[rs1] + imm
- rv64ui/addiw.s             R[rd] = R[rs1] + imm
- rv64ui/add.s               R[rd] = R[rs1] + R[rs2]
- rv64ui/addw.s              R[rd] = R[rs1] + R[rs2]
- rv64ui/andi.s              R[rd] = R[rs1] & imm
- rv64ui/and.s               R[rd] = R[rs1] & R[rs2]
- rv64ui/auipc.s             R[rd] = PC + {imm, 12'b0}
- rv64ui/beq.s               if(R[rs1] == R[rs2]) PC = PC + {imm, 1'b0}
- rv64ui/bge.s               if(R[rs1] >= R[rs2]) PC = PC + {imm, 1'b0}
- rv64ui/bgeu.s              if(R[rs1] >= R[rs2]) PC = PC + {imm, 1'b0}
- rv64ui/blt.s               if(R[rs1] < R[rs2]) PC = PC + {imm, 1'b0}
- rv64ui/bltu.s              if(R[rs1] < R[rs2]) PC = PC + {imm, 1'b0}
- rv64ui/bne.s               if(R[rs1] != R[rs2]) PC = PC + {imm, 1'b0}
- rv64ui/fence_i.s
- rv64ui/jalr.s              R[rd] = PC + 4; PC = R[rs1] + imm
- rv64ui/jal.s               R[rd] = PC + 4; PC = PC + {imm, 1'b0}
- rv64ui/lb.s
- rv64ui/lbu.s
- rv64ui/ld.s
- rv64ui/lh.s
- rv64ui/lhu.s
- rv64ui/lui.s               R[rd] = {32b'imm<31>, imm, 12'b0}
- rv64ui/lw.s                R[rd] = {32'bM[](31), M[R[rs1]] + imm](31:0)}
- rv64ui/lwu.s
- rv64ui/ma_data.s
- rv64ui/ori.s               R[rd] = R[rs1] | imm
- rv64ui/or.s                R[rd] = R[rs1] | R[rs2]
- rv64ui/sb.s                M[R[rs1] + imm](7:0) = R[rs2](7:0)
- rv64ui/sd.s                M[R[rs1] + imm](63:0) = R[rs2](63:0)
- rv64ui/sh.s                M[R[rs1] + imm](15:0) = R[rs2](15:0)
- rv64ui/simple.s
- rv64ui/slli.s              R[rd] = R[rs1] << imm
- rv64ui/slliw.s             R[rd] = R[rs1] << imm
- rv64ui/sll.s               R[rd] = R[rs1] << R[rs2]
- rv64ui/sllw.s              R[rd] = R[rs1] << R[rs2]              
- rv64ui/slti.s              R[rd] = (R[rs1] < imm)? 1 : 0
- rv64ui/sltiu.s             R[rd] = (R[rs1] < imm)? 1 : 0
- rv64ui/slt.s               R[rd] = (R[rs1] < R[rs2])? 1 : 0
- rv64ui/sltu.s              R[rd] = (R[rs1] < R[rs2])? 1 : 0
- rv64ui/srai.s              R[rd] = R[rs1] >> imm
- rv64ui/sraiw.s             R[rd] = R[rs1] >> imm
- rv64ui/sra.s               R[rd] = R[rs1] >> R[rs2]
- rv64ui/sraw.s              R[rd] = R[rs1] >> R[rs2]
- rv64ui/srli.s              R[rd] = R[rs1] >> imm
- rv64ui/srliw.s             R[rd] = R[rs1] >> imm
- rv64ui/srl.s               R[rd] = R[rs1] >> R[rs2]
- rv64ui/srlw.s              R[rd] = R[rs1] >> R[rs2]
- rv64ui/sub.s               R[rd] = R[rs1] - R[rs2]
- rv64ui/subw.s              R[rd] = R[rs1] - R[rs2]
- rv64ui/sw.s                M[R[rs1] + imm](31:0) = R[rs2](31:0)
- rv64ui/xori.s              R[rd] = R[rs1] ^ imm
- rv64ui/xor.s               R[rd] = R[rs1] ^ R[rs2]
- rv64um/div.s               R[rd] = (R[rs1] / R[rs2])
- rv64um/divu.s              R[rd] = (R[rs1] / R[rs2])
- rv64um/divuw.s             R[rd] = (R[rs1] / R[rs2])
- rv64um/divw.s              R[rd] = (R[rs1] / R[rs2])
- rv64um/mulh.s              R[rd] = (R[rs1] * R[rs2])(127:64)
- rv64um/mulhsu.s            R[rd] = (R[rs1] * R[rs2])(127:64)
- rv64um/mulhu.s             R[rd] = (R[rs1] * R[rs2])(127:64)
- rv64um/mul.s               R[rd] = (R[rs1] * R[rs2])(63:0)
- rv64um/mulw.s              R[rd] = (R[rs1] * R[rs2])(63:0)
- rv64um/rem.s               R[rd] = (R[rs1] % R[rs2])
- rv64um/remu.s              R[rd] = (R[rs1] % R[rs2])
- rv64um/remuw.s             R[rd] = (R[rs1] % R[rs2])
- rv64um/remw.s              R[rd] = (R[rs1] % R[rs2])
- rv64uzfh/fadd.s            F[rd] = F[rs1] + F[rs2]
- rv64uzfh/fclass.s          R[rd] = class(F[rs1])
- rv64uzfh/fcmp.s
- rv64uzfh/fcvt.s
- rv64uzfh/fcvt_w.s
- rv64uzfh/fdiv.s            F[rd] = F[rs1] / F[rs2]
- rv64uzfh/fmadd.s           F[rd] = F[rs1] * F[rs2] + F[rs3]
- rv64uzfh/fmin.s
- rv64uzfh/ldst.s
- rv64uzfh/move.s
- rv64uzfh/recoding.s
